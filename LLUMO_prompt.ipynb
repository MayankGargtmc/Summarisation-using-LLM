{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eysFGRD4Cvce",
        "outputId": "683f0817-1dfa-4ac6-d4b5-93c4db56f181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEV5-zgPDFsd",
        "outputId": "098336c7-5171-4ace-ce77-9656a4991d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "73mtwIHqDBl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe1  = pipeline(model = \"MayankMoon/google-t5-for-summary\")\n",
        "# pipe2 = pipeline(model = \"MayankMoon/gemma_for_summary\")\n",
        "pipe3 = pipeline(model = \"MayankMoon/output_dir\",task=\"summarization\")"
      ],
      "metadata": {
        "id": "qfl9d0VvDEBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample output of a pipeline\n",
        "pipe3(\"The authors present a class of neural process models that are able to produce correlated predictions while amenable to exact, simple and scalable maximum likelihood optimization supporting multiple outputs. By using invertible transformations (gaussian copula), the model is able to capture non-Gaussian output distributions. Experiments with artificial and real data (EEG and climate), highlight the predictive ability of the proposed model. The authors introduce a relatively straightforward extension for Gaussian neural processes in which both mean and (half of the) covariance functions are specified as neural networks, and the covariance function is either explicitly calculated as an inner product in (7) or as a squared exponential covariance function modulated in magnitude by an auxiliary neural network and calculated using the outputs of a neural network rather than the input data itself (x_t, x_c, y_c). Their multi-output and non-Gaussian strategy follows the modulated kernel and Gaussian copula formulation, respectively. Comprehensive experiments on both artificial and real data demonstrate the advantages of the proposed model over the related, but more computationally expensive, fullConvGNP model. Moreover, on real data, the proposed model outperforms both mean field, convNP and MOGP approximations.\\n\\nSomething that is not discussed in the paper is the setting of the length scale of the squared exponential kernel.\\n\\nConsidering that one of the motivations of the proposed approach is how prohibitive existing approaches are, having estimates of computational cost and/or runtime experiments could be a welcome addition to the paper. The proposed approach though technically simple relative to existing literature in neural and Gaussian process literature it is well motivated, technically sound and with comprehensive experimental results that support the improved predictive performance claimed by the authors.\", max_length = 10000000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_rrxeWDiMA",
        "outputId": "1a95460d-9db1-45e1-947e-b1f96baa914b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 10000000, but your input_length is only 392. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=196)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'The authors present a class of neural process models that are able to produce correlated predictions while amenable to exact, simple and scalable maximum likelihood optimization supporting multiple outputs. The authors introduce a relatively straightforward extension for Gaussian neural processes in which both mean and (half of the) covariance functions are specified as neural networks. The proposed model outperforms both mean field, convNP and MOGP approximations.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the jsonl file in a list\n",
        "import json\n",
        "\n",
        "with open('ORSUM_test.jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "# for json_str in json_list:\n",
        "#     result = json.loads(json_str)\n",
        "#     print(f\"result: {result}\")\n",
        "#     print(isinstance(result, dict))"
      ],
      "metadata": {
        "id": "zDExqE7mhOP4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = json.loads(json_list[0])\n",
        "json_list[393]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QzWyrNMIv_w9",
        "outputId": "93a9aed3-8df4-474a-c13d-3c6a1cfadc91"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Title\": \"Memory U-Net: Memorizing Where to Vote for Lesion Instance Segmentation\", \"Authors\": [\"Hang Zhang\", \"Jinwei Zhang\", \"Gufeng Yang\", \"Pascal Spincemaille\", \"Thanh D. Nguyen\", \"Yi Wang\"], \"Abstract\": \"Confluent lesions usually occur when pathologically distinct lesions grow close to each other and form a large spatially-connected lesion.   \\\\nThese confluent lesions pose a great challenge for subsequent image analysis and disease diagnosis, as individual lesions are difficult to separate and segment.\\\\nIn this paper, we propose a Memory U-Net that takes advantage of recent fully convolutional neural network U-Net and memory networks, to resolve the issue.\\\\nThe main idea is that we develop a hybrid model with a U-Net for feature extraction and a memory network as the alternative code book for generalized Hough voting.\\\\nTo alleviate the GPU memory overhead brought by the large code book, we decompose the large code book into three smaller ones, where each one of them accounts for voting in one specific direction.  \\\\nThrough voxel-wise voting, a density map of lesion locations can be obtained by aggregating votes from all lesion voxels, and this density map is further used to generate final instance segmentation results.\\\\nExperiments on a large-scale cross-sectional multiple sclerosis study verify the efficiency and the effectiveness of the proposed method.\", \"Review\": [{\"paper_type\": \"methodological development\", \"recommendation\": \"Accept (Poster)\"}, {\"confidence\": \"3: The reviewer is fairly confident that the evaluation is correct\", \"your_profile_and_conflicts_of_interest\": [], \"anonymity_and_confidentiality\": [], \"paper_type\": \"both\", \"questions_to_address_in_the_rebuttal\": \"Please see \\\\u201cweakness\\\\\"\", \"preliminary_rating\": \"3: Weak accept\", \"justification_of_the_preliminary_rating\": \"This paper is well-written and easy to follow. It focused on an important task of segmenting multiple instances for medical images. The proposed method is novel and well-described. The evaluation is convincing with comparisons to baselines.\", \"recommendation\": [\"Oral\"], \"special_issue\": \"no\", \"deanonymize_review\": \"no\", \"review\": \"- The proposed method is novel and well-motivated.\\\\n- The paper is written well.\\\\n- The motivation is clear.\\\\n- The description of proposed method is easy to follow.\\\\n- The reference is thorough and well-described. - Maybe provide a visual result to demonstrate the performance of the proposed method.\\\\n- Explain more details about the proposed method.\\\\n- I found Figure 2 a hard to follow. Please provide text description in caption.\\\\n- Maybe perform statistical significance test for results.\\\\n \"}, {\"confidence\": \"4: The reviewer is confident but not absolutely certain that the evaluation is correct\", \"your_profile_and_conflicts_of_interest\": [], \"anonymity_and_confidentiality\": [], \"paper_type\": \"both\", \"detailed_comments\": \"Generally, the paper is well-written and easy to follow. There are some concerns raised when going through the paper. \\\\n\\\\n1. Although this is probably the first work to perform segmentation instance segmentation for MS lesions, the related work on instance segmentation in medical imaging (e.g. cell instance segmentation) should be mentioned. \\\\n\\\\n2. In section 3.1, are the offsets for 3D localization? If yes, please clarify it and mention its format similarly with 2D object detection. The weighting for the lesion sizes seems not necessary. Please clarity it. \\\\n\\\\n3. The choice of evaluation metric. The authors use \\'symmetric best Dice score\\' but this is not clinically useful as for unseen datasets. In my opinion, it would be better to find an optimal threshold from the validation set and then use the fixed threshold for the test set. Also, the last two columns of Table 1 seem to be altered. Please carefully check. \\\\n\\\\n4. In Table 1, when comparing the U-Net and the proposed Memory U-Net, the output of the U-Net seems to be fixed offsets, thus I am not sure if it is fair to compare them given the proposed evaluation metrics which takes the maximum Dice. \\\\n\\\\n\\\\nMinor: \\\\n1. It would be great if the author could compare the method with a mask-RCNN or at least mentioning it in future work. \\\\n2. The baseline is a bit weak. How about using the LST tool + NMS or other methods to generate offsets for comparison? \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\", \"questions_to_address_in_the_rebuttal\": \"Mostly from the weakness part. Please see the following: \\\\n\\\\n1. Although this is probably the first work to perform segmentation instance segmentation for MS lesions, the related work on instance segmentation in medical imaging (e.g. cell instance segmentation) should be mentioned. \\\\n\\\\n2. In section 3.1, are the offsets for 3D localization? If yes, please clarify it and mention its format similarly with 2D object detection. The weighting for the lesion sizes seems not necessary. Please clarity it. \\\\n\\\\n3. The choice of evaluation metric. The authors use \\'symmetric best Dice score\\' but this is not clinically useful as for unseen datasets. In my opinion, it would be better to find an optimal threshold from the validation set and then use the fixed threshold for the test set. Also, the last two columns of Table 1 seem to be altered. Please carefully check. \\\\n\\\\n4. In Table 1, when comparing the U-Net and the proposed Memory U-Net, the output of the U-Net seems to be fixed offsets, thus I am not sure if it is fair to compare them given the proposed evaluation metrics which takes the maximum Dice. \", \"preliminary_rating\": \"3: Weak accept\", \"justification_of_the_preliminary_rating\": \"1. A combination of U-Net, memory network and Hough voting from three views sounds novel. Especially the motivation to solve the long-tailed problem in the specific dataset. \\\\n2. Paper is well written and easy to follow. \\\\n3. The problem aiming to solve is clinically relevant. \\\\n4. Some details need to be clarified. \", \"recommendation\": [\"Poster\"], \"special_issue\": \"no\", \"deanonymize_review\": \"yes\", \"final_rating\": \"2: Weak reject\", \"final_rating_justification\": \"The authors did not submit a rebuttal to address some raised concerns. \\\\nThus the current version may not be ready for final publication in MIDL. \", \"review\": \"1. A combination of U-Net, memory network and Hough voting from three views sounds novel. Especially the motivation to solve the long-tailed problem in the specific dataset. \\\\n2. Paper is well written and easy to follow. \\\\n3. The problem aiming to solve is clinically relevant.  1. Since the authors define the problem to be an instance segmentation problem, related work on performing instance segmentation in medical imaging should be mentioned too. \\\\n\\\\n2. Some details need to be clarified. For example, when preparing the datasets, why putting different weights according to sizes? \\\\n\\\\n3. The evaluation metrics in Table 1 seem to be altered. \\\\n\\\\n4. Maybe a bit more experiments are needed.  \"}, {\"confidence\": \"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\", \"your_profile_and_conflicts_of_interest\": [], \"anonymity_and_confidentiality\": [], \"paper_type\": \"methodological development\", \"detailed_comments\": \"* The quantitative results require a statistical significance test between different methods.\", \"questions_to_address_in_the_rebuttal\": \"* Mainly, the inclusion of the qualitative results (at least in the supplementary material) and inclusion of instance segmentation literature in the related work section with better discussion should be addressed in the rebuttal.\", \"preliminary_rating\": \"2: Weak reject\", \"justification_of_the_preliminary_rating\": \"The proposed network architecture is novel and promising. but the paper is missing key literature on instance level segmentation methods and comparison against one of them. Similarly, missing qualitative results and confusion matrix makes it hard to evaluate results. \", \"recommendation\": [\"Poster\"], \"special_issue\": \"no\", \"deanonymize_review\": \"no\", \"final_rating\": \"2: Weak reject\", \"final_rating_justification\": \"I still believe that the paper doesn\\'t include clear discussion, related work to instance segmentation, and qualitative analysis against baselines. Similarly, baselines are also really limited with no statistical significant analysis against the used baseline. I would like to keep my initial rating of weak reject.\", \"review\": \"* Introduction section is written in a really good manner with a clear formulation of the problem at hand and clear motivation for the proposed method.\\\\n* The pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List to store extracted metareviews\n",
        "metareviews = []\n",
        "\n",
        "# Iterate through each JSON string\n",
        "i = 0\n",
        "for i in range(len(json_list)-1):\n",
        "    json_str = json_list[i]\n",
        "    # Convert JSON string to dictionary\n",
        "\n",
        "    data_dict = json.loads(json_str)\n",
        "    # Extract the 'metareview' value and append to the list\n",
        "    metareview = data_dict.get('Metareview', None)\n",
        "    if metareview is not None:\n",
        "        metareviews.append(metareview)\n",
        "\n",
        "# Create a DataFrame from the extracted metareviews\n",
        "df_metareviews = pd.DataFrame({'Metareview': metareviews})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_metareviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAtYEn86z3mf",
        "outputId": "10d3da17-4e7e-460d-9204-d6b582143be8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Metareview\n",
            "0    This paper proposes a class of neural processe...\n",
            "1    Exploration can happen at various levels of gr...\n",
            "2    This paper proposes an unsupervised graph lear...\n",
            "3    This paper suggests that adversarial vulnerabi...\n",
            "4    The paper shows that a form of Fictitious Self...\n",
            "..                                                 ...\n",
            "388  Reviewers are in agreement that this work is a...\n",
            "389  The authors design an algorithm for composite ...\n",
            "390  This paper uses a masked autoencoder as visual...\n",
            "391  This paper received unanimous recommendations ...\n",
            "392  This paper presents a model to identify entity...\n",
            "\n",
            "[393 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARIZATION_PROMPT =\"\"\"\n",
        "Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning].\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Read the provided metareview carefully.\n",
        "Use the information from the metareview to generate a summary that captures the key points and findings of the paper's review process.\n",
        "Ensure that the summary is concise, informative, and accurately represents the content of the metareview.\n",
        "Your summary should be between 2 to 4 sentences long.\n",
        "Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation of the paper as evaluated by the reviewers.\n",
        "Example Metareview:\n",
        "\n",
        "Metareview: \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper was recommended for acceptance with minor revisions.\"\n",
        "\n",
        "Sample Summary:\n",
        "\n",
        "Summary: \"The paper introduces a novel neural network training approach, showing promising results in experiments. Reviewers highlighted its potential for significant advancements in the field, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions.\"\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Using the information provided in the metareview dataframe, generate summaries for each of following metareview:\n",
        "{metareview}\"\"\""
      ],
      "metadata": {
        "id": "4UyO8jnBDvx8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe3(SUMMARIZATION_PROMPT)"
      ],
      "metadata": {
        "id": "6E37IwMDdIRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3c75a3-5881-4c8f-c522-7cebe61bd9fc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Use the information provided in the dataframe to generate a summary that captures the key points and findings of the review process. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = []\n",
        "for i in range(len(df_metareviews)):\n",
        "  input = df_metareviews.Metareview[i]\n",
        "  summary.append(pipe3(SUMMARIZATION_PROMPT.format(metareview=input))[0][\"summary_text\"])\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "RelWzD7MdL9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac904f6-409b-4a8c-d6de-fb124f0f7991"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV053S3bK0FG",
        "outputId": "f2dee436-71b2-464b-f079-1345462eab30"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This paper proposes a class of neural processes that lifts the limitations of conditional neural processes (CNPs) and produces dependent/correlated outputs but that, as CNPs, is inherently scalable and it is easy to train via maximum likelihood. The proposed model is extended to multi-output regression and to capture non-Gaussian output distributions. The paper parameterizes the prediction map as a Gaussian, where the mean and covariance are determined using neural networks.',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that this paper opens up and tackles rebuttal, and provides an extensive empirical study on atari games (a standard benchmark for such problem settings). While the reviewers agreed that the paper could have been made stronger by adding an illustrative task and additional baselines.',\n",
              " 'This paper proposes an unsupervised graph learning method (IGSD) by iteratively performing self-distillation to contrast graph pairs under different augmented views. The method is empirically evaluated on some semi-supervised graph classification and molecular property prediction tasks, and has achieved promising results. Reviewers agree that the method is interesting and the paper is well-written.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is well-written, and all reviewers appreciated the easy-to-read and clear nature of the theoretical results, including the assumptions and limitations. The reviewers also agreed that the lack of data dependence and only considering the norm of the gradient considerably limit the significance of the corresponding theoretical results.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper needs a more thorough discussion on related works, the assumptions made, and the argument needs to be expanded and explained in more detail.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were on the positive side while holding some concerns about the marginal improvement over the SoTA methods, which were addressed in the author rebuttal.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. However, the reviewers argued strongly that this paper should be considered as a contribution to the VI literature and not the SMC literature. I agree with the authors that the current draft does not clearly circumscribe its contributions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that the paper is interesting and experiments well support it.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper presents a novel neural network training approach that uses an auxiliary network to learn environment-specific features, from which environment inferences can be derived. The method is composed of two jointly learned models, that take care of the environment identification, the learning of the invariant representations, and the label predictions, produced by a multi-headed neural network. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers emphasized that this is a well written [ovqB,1zPe] and sound paper [BUDa] with good theoretical [td5N,ovQB,1,1ZPe], relatively restricted Boolean task algebra [e.g.,',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. On the downside the reviewers are still not entirely convinced about the contribution and believe that the paper requires a significant re-write to incorporate the discussed points as well as an additional round of reviews.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are encouraged to continue their work on this important problem, and the review comments hopefully help in that.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers recommend acceptance. Please take the reviewers' suggestions into account, and incorporate the explanations and clarifications provided during the rebuttal in the camera ready version.\",\n",
              " 'Your task is to generate concise summaries for each metareview following the instructions above. The reviewers agree the paper brings a novel perspective by controlling the conditioning of the model when performing quantization. The experiments are convincing experiments. The reviews are convincing and the reviewers encourage the authors to incorporate additional references suggested in the reviews.',\n",
              " 'This paper presents a method for unsupervised learning of disentangled representations by first training a VAE with a tangled set of latents, then sequentially learning disentangle latent variables one at a time from the entangled initial VAE latent space. The method is shown to perform competitively with previous VAE and GAN approaches. The reviewers expressed concerns about the clarity and description of the proposed one-factor-at-a-time training procedure, and the lack of theoretical motivation.',\n",
              " 'This paper presents a rich dataset aimed at creating supervision for 2D cartoon tasks. The dataset is created by procedurally converting open source 3D computer graphics movies/shorts into \"flattened\" 2D frames. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers appreciated these aspects of the paper while highlighting potential weaknesses that appear addressed in the revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors provide computationally-efficient algorithms that are based on Bernstein concentration inequality, facilitating the improved bounds.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers appreciated the simplicity of the approach and the extensive experimental results.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions. All but one reviewer is concerned with the limited experiments, but the other reviewers, and the AC, find the experimentation convincing enough to warrant acceptance.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that this paper provides ample empirical evidence and praises the experimental value of the paper. However, some concerns were raised regarding the generalization of the approach to different datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the paper is well-written, and the techniques (using the \"tangent residual\" as a potential function) are novel. For the final version, the authors are encouraged to incorporate the reviewers\\' suggestions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper provides novel guarantees for the well-studied distributed sparse regression problem. The theoretical results improve upon the state of the art and extend to settings that many previous results could not handle. The reviewers agree that the technical contribution of the paper is above the bar for acceptance.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns were raised about generalization. Overall, the paper received a positive recommendation with minor revisions. The reviewers have responded very well to all the reviewers questions/concerns, adding significant sections to their supplement, and adding some comparisons to the camera-ready since they now have the code.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors present Neural Acoustic Fields (NAF), which render sounds for arbitrary emitter and listener positions in a scene. The reviewers are very positive (8-8-8-5).',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the current work is too thin in novelty and contribution: it provides only convergence analysis under very strong assumptions, and heavily builds on techniques from prior works. The paper does not further our theoretical understanding on why PPO is better than vanilla policy gradient.',\n",
              " 'This paper proposes a method for learning physics combining symbolic computation and learning in an interesting way, targeting sample efficiency. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were concerned about the generalization of the approach to different datasets, although some concerns were raised about generalization were noted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers all found the approach practical and empirically effective.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The theoretical results require revision as several issues have been indicated in the reviews. The reviewers have tried to correct them during the rebuttal, but the reviewers remain unconvinced.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have addressed this by pointing out similarities to their work but also noted that alternative approaches such as completely retraining the model might be more appropriate.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The major weakness is that the methodological contribution is quite limited. Projecting data into lower dimensional spaces to speed up downstream tasks is not new.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is well written and easy to follow. The main criticisms are pointed out by reviewer GZwK, with a reasoning that is not well justified.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are very supportive and one reviewer provides the lowest score of 1 and has made strong remarks that include: \"What is proposed in this paper is simply not comprehensible\", \"description of the method itself is simply devoid of all required detail\" and \"the main claims of the reviewers have a rebuttal.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers had raised concerns about the generalization of the approach to different datasets.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers find the paper well-written and find the empirical results on Alzheimer brain MRIs relevant for the neuroscience community.',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper presents a large corpus of Korean legal documents, paired with labels corresponding to two classification tasks, two legal judgment prediction tasks, and one summarization task. Reviewers praised the uniqueness of the new resource, although there are some criticisms of the results section, with several reviewers bringing up possible comparisons to other models and wondering whether the performance of this model has been analyzed thoroughly. Overall, the reviewers seem to lean positive on this and I would lean positively on this one. The reviewers are',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted that GraphNAS is very relevant and that a benchmark for them would be very useful for the community. The authors also noted that tabular NAS benchmarks should be benchmarked on as many as 9 different datasets, which may also help facilitate research on meta-learning.',\n",
              " 'This paper proposes an architecture of a policy network (WaveCorr) that is particularly effective for portfolio management tasks. The proposed WaveCorr is shown to achieve the state-of-the-art performance in a portfolio management task. The reviewers and AC understood the difference between the definition of \"permutation invariance\" defined in this paper and that studied in the prior work (the output is insensitive to the permutation of the particular values of the input). However, the Corr layer proposed in the paper appears to have significant improvements in the field of neural network training.',\n",
              " \"The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are quite positive about the paper and the rebuttal phase greatly helped clarify the paper's impact.\",\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors acknowledge that there was a bug in their code, which I believe should at least lead to softening the claims about group disentanglement.',\n",
              " \"This paper proposes a method to create cheap NAS surrogate benchmarks for arbitrary search spaces. The reviewers found the experimental results compelling, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The main sticking (and considered-as-valid) critique is on the relatively outdated and incomplete selection of baselines. Moreover, the reviewers agreed that the arXiv/NeurIPS complicacy shouldn't bring into the current discussion, and ignored that factor.\",\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers' comments are all well addressed and the reviewers seem to be satisfied with the answers.\",\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers and I think that this is an interesting paper with a compelling application. There were some concerns about theoretical novelty and biological accuracy but these were addressed during the review period.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were concerned about the generalization of the approach to different datasets, although some concerns were raised about generalization were noted.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors did a good job in replying to comments and criticisms, which has clarified some misunderstandings.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are rather lukewarm, and one reviewer is more positive (but seems less confident in his score).',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. I recommend acceptance of this paper, as it can lead to relevant directions in neuro-symbolic robotics.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The reviewers are uniformly positive, and I also voice similar praises, e.g., I appreciate the extensive discussion in appendices A and B, and the detailed experiments in the later annexes. As such, it is easy to recommend acceptance.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agreed that the paper is simple and reasonable, and the results on a variety of goal-conditioned RL benchmarks are quite comprehensive and strong. While there were concerns about why the proposed discretized representation forms a semantically meaningful latent space, and where the improvement comes from,',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about generalization of the approach to different datasets.',\n",
              " 'This paper proposes a method for learning sparse DNNs which consists of three components: First, a \"dense\" network is maintained and updated in each backwards pass, but the forward pass is done via a sparsified version of the network; sparsification is done through \"soft\" thresholding; and the sparsity ratio is increased over the course of training. The consensus was therefore to reject the paper.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors have also given a detailed proof that the denoiser reduces the required complexity of the predictor. The reviewers have also provided a clear proof on the reduced complexity requirement for the predictedor. However, some concerns about generalization were raised regarding generalization of the approach.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. Overall the paper is overall well written and clearly presents the results. Some concerns are raised regarding the tradeoff between asynchrony and robustness.',\n",
              " 'This paper studies post-training quantization by proposing Network-Wise Quantization (NWQ) an end-to-end quantization approach that takes into account relationships between layers rather than treating layers independently. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors also expanded their discussion of these works in their updated manuscript, clarifying the differences.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers raised a number of concerns about the paper, including the fact that the layerwise training results validate the information bottleneck theory of deep learning.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. Both theoretical analyses and empirical studies have been reported in this paper.',\n",
              " 'The paper presents a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about the clarity of the paper regarding the structured causal model considered and its applicability beyond image generation, experimental protocol for choosing hyperparameters (loss scaling and ratios of real data and interventional samples) and some missing references. I think the paper will be good addition to ICLR program.',\n",
              " \"The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have provided detailed and constructive feedback for improving the paper. The authors should incorporate the reviewers' feedback to better position the work w.r.t. the existing literature on data augmentation and state of the art results, better motivate the data hausse strategies in the context of educational applications.\",\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers recommend acceptance and appreciate the promising empirical results.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers expressed concerns about generalization of the approach to different datasets.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have done a good job in addressing most of these concerns with documentation, an API, and example notebooks.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the presented resource addresses a need for models that can be held more accountable in terms of geographic diversity and demographic diversity.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about generalization of the approach to different datasets, although some concerns were raised regarding generalization were noted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The technical novelty of the paper is sound, with the thorough theoretic motivation of the proposed method and solid experiments. The presentation of this paper is also satisfactory.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were responsive to reviewers comments and have respectively improved their paper by adding experiments, including an ablation study of each component of the objective function, study of the effect regularization on unbalanced class distributions, and reporting accuracy on pseudo-labels.',\n",
              " 'This paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers were concerned about the novelty [bRWC], unimpressive qualitative results [gw2r],',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that this paper comprehensively studies a fundamental question of PAC learning under instance-targeted poisoning, including the study of realizable, agnostic, deterministic learning settings; overall this paper makes a nice contribution to the field of robust machine learning.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers noted that the paper introduces interesting ideas and that the use of Ricci-curvature/flow is a promising contribution. However, there are still concerns about the current version of the paper.',\n",
              " 'This paper proposes a learning-based method for shape registration that conditions on regions of the shape rather than learning from the entire point cloud in one shot. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted several questions about the method, thanks to expository issues as well as missing comparisons/ablation studies.',\n",
              " \"This paper addresses the HRI challenge of measuring how well a robot has learned a user's reward function. The reviewers agreed that the paper is well written and easy to understand. Overall, the reviewers recommended acceptance with minor revisions. Reviewers noted that this is a non-standard paper, but it raises interesting and potentially provocative points that would be great for the CORL community to discuss.\",\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of each review. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advances in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that these contributions are interesting to the larger community and that the presentation of the results is clear and straightforward. The main issues raised by the reviewers were carefully addressed in the rebuttal.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers acknowledged the importance of the studied problem setting and generally appreciated the results.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors present a compelling case study describing literate programming.',\n",
              " \"The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper's strength is in that it shows the log likelihood objective is lower bounded by a GAN objective plus an entropy term. The authors addressed the issue with some new experiments with linear generators and quadratic loss, but it lack experiments with deep models which seems to be\",\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers acknowledge that the paper improved greatly during the discussion phase: clarification of motivations, of experimental settings and results, of discussion with previous work. However, despite those improvements, the submission is not yet ready for publication at ICLR.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the paper addresses a relevant topic, proposes an effective method, and is well written.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. However, some concerns were raised regarding the generalization of the approach to different datasets, although some concerns about generalization were noted. The reviewers also noted that the paper is not novel in itself, as is the claim that new tests have been devised.',\n",
              " 'This paper proposes a novel communication-efficient learning method that significantly reduces feature size and communication traffic. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The reviewers raised a common concern regarding the lack of focus on the actual usefulness of the librabry in improving the performance of the models that is applied on.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers unanimously vote for rejecting the paper.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about the generalization of the approach to different datasets, although some concerns about generalization were raised regarding generalization. However, the reviewers agreed that the paper is worthy of study, and that a complete theoretical justification is lacking.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the contributions are significant and well presented, and appreciate the author feedback to the reviews.',\n",
              " 'This paper presents a novel neural network architecture to predict interacting residues among two interacting proteins, and evaluates its performance on benchmarks. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors have added a comparison to MEPOL, and in these experiments, APT outperforms this method, sometimes by some margin.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about the generalization of the approach to different datasets, although some concerns were raised about generalization were noted.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are generally not very enthusiastic about the paper, with scores hovering at or just below the acceptance threshold. The authors are not communicating clearly what the paper contributes and why.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received positive rates thanks to reasonable proposed ideas and thorough experiment evaluation. The camera-ready version may need to be updated to fully reflect reviewers comments and answers to them.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers expressed concerns about generalization of the approach to different datasets, although some concerns were raised regarding generalization were noted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers addressed the concerns raised by the reviewers regarding the selection of the compression quality q as far as I am concerned, and conducted additional experiments to further demonstrate the usefulness of the approach.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were satisfied with the response, and K314 upgraded their rating to 6, while other reviewers maintained 5s.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers did raise some valuable concerns that should be addressed in the final version of the paper.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers were positive, however the most confident reviewer was negative. The paper is titled knockoff-free, which means that both 1) 1-bit p-values are not used and 2) The full knockoff property is not required, only sampling from complete conditionals is required.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that this work is novel and technically sound, and their concerns were mainly related to the breadth of tasks explored in the initial submission. During the review process the reviewers have gone to considerable effort to introduce new tasks (e.g. DrawerWorld, Robosuite and',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. Cons: There are three major concerns raised by reviewers: (1) clarity, (2) relatively thin experimental results, (3) novelty, and (3) novelty. The reviewers also raised concerns about insufficient component-wise evaluation (e.g., text classification from topic models) and insufficient GAN-based baselines.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers suggest acceptance of this paper, which reports the relationship between perceptual distances, data distributions, and contemporary unsupervised machine learning methods.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors propose the temporal quantile adjustments (TQA) that can improve longitudinal coverage for the prediction interval built for regression on cross-sectional time series data. The paper has solid empirical support and decent theoretical guarantees. The research questions addressed in this paper are of critical importance for practitioners in relevant areas.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were mixed here and all quite borderline. There are legitimate points raised for why this is being consistently given borderline ratings, with two in particular resonating with my own reading (novelty and comparison with other methods). However, despite these issues the paper is a solid contribution.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper was recommended for acceptance with minor revisions.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors use this attribute to formulate tailored off-policy actor-critic algorithms, for both MDPs and RMABs which are gradient-based, so can utilize neural networks.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have provided satisfying clarifications during the rebuttal period that convinced reviewers to increase further their scores. The current consensus is that the paper deserves publication.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were disappointed by the reviewers' rebuttal, but we believe further substantial improvement will make this work a much stronger contribution.\",\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers concluded that the contributions are conceptually interesting and somewhat novel.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted some concerns about generalization, although some concerns were raised regarding the generalization of the approach to different datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were gently pushing the authors towards a very strong assumption.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel and non-trivial method for approximating the eigenvectors of the Laplacian, in large or continuous state environments. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. It is an important advance towards this goal, and will be of interest to many that would like to learn state representations based on the geometric information given by the Lalacian.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The proposed approach falls short in comparison to the slot gated attention work by Goo et al.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main topic of this work is stochastic bilevel optimization. The reviewers are unanimous that this is well-presented work of high quality and should be accepted, and so do I.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes an approach for learning a decomposition of a scene into 3D objects using single images without pose annotations as training data. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers point out that the method is reasonable, and the results are promising but somewhat inconclusive, so I recommend rejection at this point, but encourage the authors to resubmit to a different venue.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the method makes sense and addresses an important problem of transfer in RL. The authors did a good job in the rebuttal to empirically validate their claims and provided extra experiments.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors argue that this leads to estimators that are better than the purely supervised estimator under a rather weak assumption called MCAR - which assumes that the probability of a missing label is independent of covariate and label.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that the paper is well-written and the contribution nicely presented.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main contributions of this work are a negative-negative-aware module (PNM) and weakly-supervised cross-slide contrastive learning (WSCL) module and a loss to encourage intra-WSI local patch separation and inter-WWI global feature contrast.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted its potential for significant improvements in the field, although some concerns about generalization were raised regarding the generalization of the approach to different datasets.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors only conduct experiments on improving LogP, which is a benchmark that is too easy and not challenging. The main claim of the paper is not supported by ablation study.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were not satisfied with the reviewers' feedback.\",\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions. The reviewers and authors have extensive discussion.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are split in their opinions (three in favor of acceptance; three opposed). The main argument raised against the paper is that it does not introduce a new benchmark or dataset, and does not make falsifiable claims.',\n",
              " 'The paper proposes a novel approach to neural network training using two theoretically inspired heuristics: the condition number of the Neural Tangent Kernel (to measure \"trainability\" of the architecture), and the number of linear regions in the input space. The two heuriistics are negatively and positively correlated with test accuracy, respectively, allowing for fast, training-free Neural Architecture Search. The authors propose a new method to train-free neural architecture search using a combination of theoretically-inspired e.g.,',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about the generalization of the approach to different datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers feel positively about the paper, agreeing that it tackles an important problem and that it provides a solid contribution.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers agree that the combination of two significantly different types of reasoning is a promising direction.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were in agreement on acceptance and concerns raised by the official reviewers and public comments should be addressed in the final revision.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that the idea of using Hamiltonian dynamics is interesting and novel. The main contribution is the proposal to model the motion space using HELO. The latent space is decomposed into a content space and a motion space, and the main contribution to the proposal is the',\n",
              " 'This paper introduces SUNMASK for modeling discrete sequences. It builds upon previous works such as SUNDAE, Coconet and order-agnostic NADE, but uses a masking scheme that enables fine-grained or human-in-the-loop control during the generation. The reviewers are concerned about the novelty and experiments of the paper, and that they do not show much improvement over SUNDE. Overall, the reviewers received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers were concerned about the conceptual gap between the problem proposed in the introduction and the extent of the experiments. The author response clarified their goal of estimating the states of the objects in the world, which they state is different from the goals of long-term object tracking and object reidentification',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the proposed work is innovative and makes a significant technical contribution in using pretrained models under weak supervision.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper has improved significantly through the interactive peer review of a dedicated set of reviewers combined with prompt responses from the reviewers.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The experimental section is comprehensive, with several benchmarks, and show clear improvements. The reviewers agree that the contributions of this paper are significant. The paper is well motivated and well explained, easy to follow.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers showed experimentally that the proposed method works well compared with other existing methods, although some concerns about generalization were raised regarding generalization.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. However, there are several concerns raised by the reviewers regarding the generalization of the approach to different datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the paper studies an important problem and that the promised multi-cloud optimization dataset could spark more research in the area of cloud optimization. The authors agree that this paper studies the problem of choosing the best cloud provider for a task.',\n",
              " 'This paper introduces a new dataset for evaluating disentanglement and its impact on out of distribution generalization based on the trifinger robotics platform. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were divided on the work, but had a number of concerns regarding the claims of novel architecture, comparisons to baselines, and issues with the clarity of the paper.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have provided detailed responses to all reviewers concerns and concerns and updated their manuscript. The authors acknowledge limitations and future work avenues.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that this work presents the very right way to describe the continuous-time version of diffusion models on discrete space, and thereafter inspired techniques make a desired contribution to the community. Some concerns are raised, including still inferior performance than the continuous counterpart, and on the independence among dimensions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The major concerns about the paper are that (1) There are too many hyper-parameters, such as those needed for ADMM.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The AC is hopeful that the paper can be significantly improved by - sufficiently discussing and highlighting the novel insights of the results, and - a more rigorous definition of \"novel\" vs. \"irrelevant\" inputs.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is a nice addition to the developing theory of implicit bias in neural training. The results are fairly involved due to the adversarial component.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviews are divided: three reviews give a score of 7 (accept) whereas one review gives a rating of 4 (borderline reject). The negative review cites lack of clarity as the main weakness, while the reviewer is not convinced about the originality of the method given similar advances in the field of predictive coding.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers raise multiple concerns about the following: Novelty (all reviewers) - Inadequate comparison baselines (all reviewingers) and Inadequacy citations. Recommendation is reject.',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers all agree that this is a strong paper worthy of publication. The paper provides a substantial extension to the prior work on nondeterministic stack models and progresses this line of research toward practical applications.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main concern is clearly the fact that this paper does very little to set itself in context, and I strongly encourage the reviewers to address these concerns.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers and AC agree that the main strength of the paper is that it studies a rather important question of the validity of using linear interpolation in evaluating GANs.',\n",
              " 'The paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have changed their assessments to accept, though would be preferable if quantitative assessment of the quality of the semantic parts (for example, by segmentation masks) could be provided.',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers and I found the reviewers' replies and rebuttal especially helpful in reaching our decision.\",\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. Both R3 and R1 argue for rejection, while R2 argues for a weak accept. Given that we have to reject borderline paper, the AC concludes with \"revise and resubmit\".',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors have tried to respond to reviewers' comments along with adding more experiments to address the problem of unauthorized use of data. In addition, considering the conferred unlearnability is found fragile to adversarial training, robust error-minimizing noise is then introduced to reduce the adversarially\",\n",
              " 'The paper presents a novel idea of a 2.5D segmentation approach considering the characteristics of medical imaging data. The practical importance and novelty of the proposed approach are well received by all the reviewers. Clear description and illustration are included appropriately in the paper. Some experimental details-related questions were raised in the rebuttal.',\n",
              " 'This paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the topics investigated in this paper are important and relevant to the field, and that the paper is an important milestone for the community.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main result is an algorithm with query complexity scaling near-linearly in the dimension. The algorithm is evaluated on synthetic and real-world datasets.',\n",
              " 'The paper proposes a novel neural network training approach to perform signal processing tasks on a signal represented with an implicit neural representation directly in the representation space, without the need to instantiate the signal. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also found the idea original, and the quality and clarity of the paper to be high. The paper is likely to inspire work that will push the idea further.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers found this paper well written and the idea of using BEV to be interesting. The main concerns raised by the reviewers include empirical evaluations of the model interpretability, justification for relying on algorithmic priors than parameters, results on more challenging datasets, and clarifications regarding the',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The AC agrees with Reviewer 2 that the paper does not provide sufficiently interesting insights beyond this observation and is unlikely to influence practical applications of these methods.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers appreciated the clarity, the mathematical rigor and the empirical evaluation of this paper.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The paper considers the stochastic proximal point algorithm, the main contribution is a convergence proof (in addition to argument that it is practical for ERM problems). However, reviewers agree that this invalidates the core results.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers had a number of questions regarding experimental setup, which were largely answered in the rebuttal.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also found that the empirical results suggest that spectral clustering-based method can be competitive with SOTA methods on node classification benchmark is an interesting result, and the empirical evaluation lacks depth and details to be really informative (eg, to understand why some methods work on some benchmarks).',\n",
              " 'This paper proposes a self-exciting temporal point process model with a non-stationary triggering kernel to model complex dependencies in temporal and spatio-temporal event data. The kernel is represented by its finite rank decomposition and a set of neural basis functions (feature functions). The proposed model has superior performance in comparison to other state-of-the-arts methods. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper has been deemed very hard and demanding to read and understand for a general machine learning crowd and even by experts in the fields of optimal transport and Markov theory. The AC strongly suggest that the authors work on a more pedagogical introduction and explanation before resubmitting.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The reviewers raised a number of concerns including the appropriateness of the chosen application and the terms in which social dilemmas have been discussed, the lack of explanations and discussions, missing references, and the extent of the evaluation studies.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main idea of the algorithm is to exploit the iid-ness of the problem and detect misreports from the underlying CDF using Dvoretzky-Kiefer-Wolfowitz type bounds.',\n",
              " 'This paper presents a knowledge distillation method for face recognition, by inheriting the teachers classifier as the students classesifier and optimizing the student model with advanced loss functions. The reviewers appreciate the simple yet clear methodology illustration and the well written paper. However, a number of major concerns are raised by the reviewers, including limited novelty, lack of comparison with more advanced knowledge distillations methods and their special case in face recognition. The ACs agree that this paper is not accepted at its current state.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed some concerns about generalization, although some concerns were raised regarding generalization of the approach to different datasets were noted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The rebuttal provided addresses some concerns, but there are still some remarks that require clarifications en work.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers consider the paper generally novel and effective, and the experiments thorough.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers felt that the paper would have been stronger if it tried to do less but better. The reviews describe in detail what the reviewers would have found compelling, but the key suggestion is to remove the complexity that is not essential for the approach to provide consistent improvements.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also raised concerns about the novelty of the proposed method and the significance of the results compared to competing methods.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers generally agreed that the empirical set up of the paper was convincing, but they also felt it over-emphasized empirics over a deeper understanding of the phenomena observed.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted some concerns about generalization of the approach to different datasets, although some concerns were raised regarding generalization were noted. The paper is well written, the approach is novel and its usefulness demonstrated on a number of different experiments.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the contribution is relevant to the workshop and presents a solid work.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers found that the paper was well-written, clear, and interesting. However, there were significant concerns with the manuscript that were not fully addressed in the revision.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers generally praised the originality, technical quality, and empirical results of the paper. They found the idea very interesting and novel, and technically sound, and the numerical results were judged to be compelling and fair.',\n",
              " 'This paper presents a method for preventing slips in point-to-point motions while grasping an object using LSTM-based models for detecting and predicting slips. This approach is effective when contact force cannot be increased. Reactive controllers are presented, and the latter demonstrated better performance. The authors successfully addressed most of the concerns raised by the reviewers, while expanding the dataset and examples will be addressed in a future paper.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors present strong empirical results on DBLP5L containing 5 languages on all 3 tasks. The results are reproducible as both the code and data are made public.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The authors show the effect of RNI on the expressive power of GNN for the first time, where the RNI was initially proposed in Sato et al. 2020.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers commented on the importance of the question related to how much selectivity is needed from units of a neural network for good classification.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers recommend rejection due to limited novelty and insufficient experimental analysis.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The main motivation is to determine how much of the overall learning is bottlenecked specifically by representation learning. The main findings are that vanilla learning gives brittle long-tailed representations, harming overall performance.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of each review. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All three reviewers recommend acceptance, to varying degree. The paper will be a valuable contribution to the program at ICLR.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that this is a reasonable contribution but that it is also extremely limited in scope. The authors suggest that their technique could apply to \"any data mixing method with \"batched k-sum\" structure.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is interesting, yet sometimes difficult to follow, and I am not certain that its quality justify acceptance.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were surprised that the paper made no mention of prior works on maximizing mutual information between features of neural networks to improve results.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have provided detailed responses to all reviewers concerns and concerns and updated their manuscript. The authors acknowledge limitations and future work avenues.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have appreciated the direction where VAEL is heading and the importance of integrating constraints in deep generative models.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received mixed reviews with borderline scores. The reviewers raised concerns about baselines and evaluations, some of which the reviewers promptly addressed in the revision during the rebuttal period.',\n",
              " 'This paper proposes a novel method for continual learning that modifies the direction of gradients on a new task to minimise forgetting on previous tasks without data replay. The method is mathematically rigorous with a strong theoretical analysis and excellent empirical results across multiple continuale learning benchmarks. The paper is a clear accept. The authors are encouraged to make sure that these points are addressed in the final version of the paper.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have improved their scores after the rebuttal, and I agree that the work has value. The work is more similar to the former OOD graph representation works than IRM & REX, since both IRM and REX require the support of the environments in test to be a subset of the',\n",
              " 'This paper presents a way to use a translation memory (TM) to improve neural machine translation. The proposed model uses a n-gram retrieve matching sentence (or pieces) and takes advantage of the useful parts using gated attention and copying mechanism. The authors should give a better exposition on the ranking mechanism.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree to reject.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted that the position of this paper compared to earlier related work is unclear, and the empirical evaluation of the method should be strenghtened.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers praised the strong performance when compared with previous work, and the evaluation clearly shows the benefit of the proposed contributions in terms of performance. The authors promised to include the missing references into the comparison.',\n",
              " 'The paper presents a new method for generation of backdoor attacks against deep networks. The new method uses global warping instead of noise patches which makes the attack much more stealthy than previous approaches. The paper is a novel and original contribution which is likely to advance the understanding of attacks. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers were generally satisfied with the paper.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors argue that applying the method to the forward diffusion in LSGM will result in $hatp_rne p_r$. However, the lack of invertibility is mentioned as one of its drawbacks.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. The reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. The reviewers agree that this paper overcomes a number of difficult algorithmic and technical challenges in parallelizing the RED method for image reconstruction. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the reviewers recommended acceptance with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers appreciate the simplicity of the method, convincing experiments and the potential practical importance.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. The reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers concerns are around the size and difficulty of the dataset; the authors successfully address those concerns during the discussion and revision period.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. The main concern that was raised with this paper is the validity of the proposed task itself.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the benefits of the proposal outweigh its flaws.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers like the work and note that *a rigorous and principled approach is taken by this work*.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. Overall the reviewers still seem to be on the fence about this paper.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper studies semantic type detection. The problem is of practical significance to i tabular data.',\n",
              " 'The paper presents an actor critic type of method consisting of two types of features -- dynamics and tasks, in the multitask continuous control setting. The reviewers have concerns with the novelty and technical significance of the work. The authors are encouraged to pursue more difficult settings and modify the method to work on those problems. This would make the paper stronger, and lead to a more novel method evaluated on harder problems.',\n",
              " 'The paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main downsides of the paper as discussed by the reviewers are the lack of experiments and somewhat stringent assumptions needed in the analysis.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers like that the authors present a new unsupervised approach, and are happy with the thorough experiments. The authors also point out that the approach could be motivated better, and that it makes many assumptions that are not explained properly. We recommend acceptance but nudge the reviewers to consider the reviewer suggestions.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"This paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed some concerns regarding the initial write-up of the paper, and the reviewers showed extraordinary diligence in assessing the authors' work.\",\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that the paper has value and proposed a fairly novel idea. This method is solely applied to digital pathology images and deserves future work.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers raised some concerns about generalization, although some concerns were raised regarding generalization of the approach to different datasets were noted.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. The reviewers agree the paper studies an interesting problem on training robust binary neural networks and the paper does a good job in evaluating the proposed approach on multiple datasets and compare well with baselines. However, the proposed method has limited novelty and is a combination of existing techniques, missing comparisons to standard training based approaches, evaluations limited to ResNets.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that novelty is low -- one would like to use any applicable method for controlling overfitting when doing transfer learning',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have expressed concerns about the generalization of the approach to different datasets, although some concerns were raised about generalization were noted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers acknowledge the quality and importance of the dataset. The authors have improved their experiments with more anomaly detection models. The new results corroborate the previous conclusions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about generalization of the approach to different datasets. However, the novelty of the method is not enough, as the domain classifier and the gradient reversal layer are the same with those methods in domain adaptation.',\n",
              " 'The paper proposes a novel neural network training method called WPipe. The method works by replacing the two-buffer structure of PipeDream-2BW with a two-partition-group structure, allowing resources to be shared in a similar way to Pipedream-1BW but with less memory use and less delays in weight update propagation across stages. The reviewers expressed concerns about the work being incremental and difficult to follow, and the reviewers did not consider novelty to be a disqualifying concern.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions.\" Overall, there is considerable merit in the work and recommend acceptance of the paper. In the camera ready, the authors should make sure not to overstate the applicability of their method.',\n",
              " 'This paper proposes and analyses a bucketing method for Byzantine-robustness in non-iid federated learning. The main concerns are related to the clarity of the technical contributions, and unclear technical statements. The reviewers are generally strongly positive about the strength of the manuscript contributions. The authors are encouraged to make the final changes agreed in the public discussion.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main pro is that analysis is important and does a thorough job at it and draws some useful insights. The reviewers are mostly very positive about the paper.',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns were raised about generalization. Overall, the paper received a positive recommendation with minor revisions. The reviewers are generally positive about the paper, and the reviewers were satisfied with the reviewer's comments.\",\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\"',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are in agreement that the paper should be rejected.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that the work is technically solid and the contribution is significant.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. I strongly encourage the authors to take the several fantastic points raised by the reviewers while crafting their next draft.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. In general, all reviewers agree with the acceptance of this paper.',\n",
              " 'This paper proposes an algorithm for training sequence-to-sequence models from scratch to optimize edit distance. The algorithm, called optimal completion distillation (OCD), avoids exposure bias problem inherent in maximum likelihood estimation training, is efficient and easily implemented, and does not have any tunable hyperparameters. The reviewers expressed concerns about the relationship of OCD to methods such as SEARN, DAgger, AggreVaTe, LOLS, and several other papers.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the contributions made by the paper are significant and can help improve related applications like ASR. The authors propose an algorithm for enhancing noisy speech by also accounting for the phase information.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers all believed the paper had contributions which would be interesting to the community (such as R1: \"the paper presents an efficient way to compute the convolutional kernel, which I believe has merits on its own\" and R2: \"I really like the idea of authors that kernels based on',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, showing significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers recommended that the paper not be accepted at this time, and this evaluation was not challenged by an author response.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets.',\n",
              " 'The paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviews indicated that the overall proposed method of fine-grained controlled generation with self-supervision is valuable, and empirical results support its effectiveness. However, some reviewers initially raised concerns regarding clarity and lack of human evaluations.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper presents a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers disagreed with the attritue that the comparison on 1 language is sufficient given the recent progress of code summariziton. The authors also provide a preliminary study of human evaluation on the generated outputs.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed a lot of interest in the topic and valued the novel application to salamander retinal data.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers consider that the proposed method is fundamental and useful.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have raised a number of concerns regarding the generalization of the approach to different datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers and AC opinions were mixed, with reviewers either being unconvinced about the novelty of the paper, or expressed issues about the clarity of the presentation.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers generally liked the paper. The technical idea is simple, but the evaluation is substantial and makes a convincing case about setting a new state of the art.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"This paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have voted to weak accept, but it is not demonstrated that (1) and (2) is an actual problem in practical applications. The paper is the first I've heard suggested that sensor mismatch between humans and autonomous vehicle sensors is the bottleneck for performance.\",\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewer 4 is concerned about motivation, reviewer 3 rightly points out that there exist numerous works that use some form of spectral layers in a deep setting on challenging datasets. Reviewer 1 reverberates the same comments regarding insufficient experiments, comparisons and limited motivation.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are in agreement that this is a well-motivated paper and should be accepted.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are extremely short, and offer no substance to justify their scores. I agree with R2 that this paper is very borderline, and that the presentation of the inference techniques for V-NMN is complex and its presentation could stand to be significantly improved.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers welcomed the experimental investigation of new phenomena in training neural networks with binary weights, but commented the overall technical quality of the work was somewhat substandard.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers identified a significant drawback of memorization in AT that could result in robust overfitting and propose a new algorithm to mitigate this drawback.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were unanimous in their opinion that the paper is suitable for acceptance to ICLR.',\n",
              " 'The paper presents a method of training two-level hierarchies that is based on relatively intuitive ideas and that performs well in outperforming the alternative baselines. The results are locomotion focused and there are only two timescales. Overall, the paper will make a good contribution to ICLR 2019.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers appreciated the novelty of this paper and the importance of scaling neural combinatorial optimization for large-scale instances.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers also expressed concerns about the generalization of the approach to different datasets.',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the paper tackles an important problem with interesting methods, that it is well written and has strong results. The main concerns raised by Reviewer jddf were about clarifying the connections to the robust optimization literature and evaluating on OOD relations.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, but some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the paper has certain merits, and on the other hand, they raised some concerns regarding some missing technical details, whether the empirical finding could be trusted, and the comparison with some highly related papers. The authors did a good job in their rebuttal, which is based on the results of the reviewers. The paper studies the behavior cloning based strategies of offline RL algorithms.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main issue raised by the reviewers is that the algorithm design and analysis appears to be based on well-known existing techniques for simpler settings. The reviewers agreed that the main results are technically challenging and likely to be useful starting point for future work on learning Markov games with function approximation.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. The reviewers agree that the idea of introducing structural biases in the attention mechanism is interesting but the results and presentation right now is not convincing. The reviewer agrees that the paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The AC feels that there is enough support from reviewers to accept the paper.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The reviewers unanimously agree that the theory here exhibiting particular case where Gaussian process priors are inferior to deep Gausssian processes is interesting, and furthermore that the proof techniques themselves are novel.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers have responded to this by suggesting the use of proxy model techniques. There are also questions about learnability of data utility.',\n",
              " 'This paper presents a new task and model for predicting the hierarchical structure of organizations / institutes. The model predicts is-ancestor relationships between the institutions by modeling the set operations between the strings. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main goal of the paper is to develop a new adaptive strategy to remove the need of hyperparameter fine tuning, which hinders the performance of DGS (Zhang et al., 2020) method.',\n",
              " 'The paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed with the reviewers consensus and recommended accepting the paper.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of each review. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that the paper is not strong enough for ICLR.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is well written and organized. The formulation is novel and technically sound. The authors presented the motivation for each part of the framework well. The reviewers had several detailed suggestions and questions, including sensitivity to hyperparameters and additional citations.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The AC agrees that the paper is not ready for publication at ILCR.',\n",
              " 'The paper presents a novel neural network training approach for combinatorial optimization problems based on the Transformer architecture. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were also concerned with scalability and theoretical basis, and I recommend accepting the paper.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The theoretical contributions of the paper are subsumed by a number of prior works (which were not initially cited).',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted that in its curent form the paper is not fit for publication. However, the reviewers pointed out missing references, issues with the abstract, lack of motivation for some of the algorithmic choices, limited novelty over clarity in the description of difference w.r.t. previous work',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the paper is technically quite strong and that it's quite well written. The authors also introduced re-weighting and rejection sampling ideas that speed up coupling from the past by using an approximate learning algorithm. These techniques could be useful in other applications, as the authors hint.\",\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are strongly in favor of acceptance. The paper is very well written and enjoyable to read.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also reviewed the paper in terms of clarifying the meaning of \"overparameterization\" in GAN training. The main concern of R3 is that the GAN formulation analyzed in the paper is mainly doing moment matching between the generator distribution (produced from a fixed finite',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are overall positive about the novel insights that the paper provides.',\n",
              " 'The paper presents a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers and AC opinions were mixed, with reviewers either being unconvinced about the novelty of the paper or expressing issues about the strength of empirical evidence supporting the claims.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are in agreement that this paper provides a minimax optimal solution to the problem of offline linear contextual bandits.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Reviewers agreed this paper should be accepted, especially after seeing that ICLR',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also agreed that the experimental validation was currently too limited, in type and size of task and data, as in scope.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The methodological contributions and technical novelties are relatively small, but the dataset is very useful. Therefore, the dataset should be publicly released; otherwise, this contribution cannot be realized.',\n",
              " \"The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers also raised a number of issues with the paper: (1) the evaluation appears a bit preliminary, and could be improved significantly with additional datasets and more ablations/comparisons; (3) the reviewers made a significant number of changes and improved parts of the paper in response to reviewers' concerns.\",\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper studies offline RL, which is an important topic in high risk domains. This method is pretty general and could be paired with other pessimistic model-based RL methods.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main issue is that MTL results in more extraction of information and that is hard to disentangle from the disentanglement metrics used.',\n",
              " 'This paper introduces sparse modeling-inspired regularizations to improve deep neural network-based image generators. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The AC agrees with that summarization and recommends rejection.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper studies the approximation properties of group convolutional neural networks. It establishes the cc-universality of group CNNs, i.e. that such networks can approximate any continuous function over any compact set, using a new constructive approach which is based on the',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" The AC encourages the authors to revise the work in response to the reviews. The reviewers expressed concerns about the scope of the work, although some concerns were raised about generalization.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns about generalization were raised regarding the generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper presents a new NAS benchmarks for hardware-aware NAS. For each of the architectures in the search space of NAS-Bench-201, it measures hardware performance (energy cost and latency) for as many as six (very different) devices. This is extremely useful for the NAS research community, since it takes very specialized hardware domain knowledge (including machine learning development frameworks, device compilation, embedded systems, and device measurements) as well as the hardware to make these measurements on up to six different hardware devices, e.g.,',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main contribution of this paper is 1. to give a characterization of sample complexity for estimating the moment tensors when the input distribution comes from a mixture of Gaussian; 2. to give an local convergence result when the samples come from an input mixture.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The review highlights numerous problems with the current progress of the work.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.\" Overall, reviewers agree that this is an interesting and important direction for research. The authors have improved the related work sections during the rolling discussion but overall the positioning of the new method has still to be improved, including a better empirical comparison across different datasets.',\n",
              " 'The paper presents a new Bayesian optimization method based on the Gaussian process bandits framework for black-box adversarial attacks. The method achieves good performance in the experiments, which was appreciated by all the reviewers. However, the presentation of the method is quite confusing, which currently precludes acceptance of the paper. The authors are encouraged to resubmit the paper to the next venue after significantly improving and cleaning up the presentation.',\n",
              " 'The paper presents a method to regularize the discriminator in GAN training with a ranking loss based on the user preference for a desired set within a larger dataset. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers are strongly in favor of the paper's contributions, and the author responses have helped clarify several aspects of the presentation and connections to existing work.\",\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main issue with this work is that the authors appear to be unaware that the basic problem they pose is solved in a more comprehensive and lossless way in an earlier work https://arxiv.org/abs/2102.12099 (Feldman and Talwar, ICML 2021)',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper is well-written and the work is promising.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper presents strong empirical evaluation on standard benchmarks, and the authors are expected to account for the discussion and suggestions in the next iteration of the manuscipt.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed that the core innovation of the paper was interesting and empirically worked reasonably well. The paper is also somewhat theoretically rigorous and provides insight into the problem.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors are strongly encouraged to release their code (including training details for reproducing ImageNet results) as the improvements they present are central to the acceptance.',\n",
              " 'This paper presents a closed loop planning system that leverages LLMs for providing candidate plans given the success of action execution and the world state. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers noted its potential for significant advancements in the field, although some concerns about generalization were raised regarding the generalization of the approach to different datasets.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All the reviewers recommended acceptance of the paper.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The main concern is the novelty and significance of the proposed method.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors are encouraged to discuss similarities to NeuraWarp and pointcloud->SDF methods in their revision.',\n",
              " 'This paper presents a significant collection of unlabelled signing data (4.6K hours) across 10 sign languages, which have been pre-processed and converted to pose-keypoints to remove identifiable information. The paper also presents Multi-ISLR a multilingual dataset with label-alignment extracted from 11 other labelled datasets for 7 sign languages. The reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors propose a simple solution to this problem, take top-K most frequently chosen items, and prove that it is near optimal. The reviewers liked the paper and I support acceptance.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions. The reviewers agree that this work is original and sufficiently empirically motivated for acceptance.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. Both reviewers and the authors have engaged in a constructive discussion on the merits and claims of the paper.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The motivation for using semi-supervised learning is clear in order to reduce the cost of acquiring dense expert annotations.',\n",
              " 'The paper introduces a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers believe that the theoretical contributions are solid and qualified to be published in NeurIPS.',\n",
              " 'The paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers, including myself, find the paper a solid contribution to the methodology and analysis, and the rebuttal did a good job address them.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. All reviewers agree that this dataset has potentially be used as a standard benchmark to measure progress in this domain. Therefore, I recommend acceptance of this paper.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers were unanimous in their vote to accept. The theoretical insights and empirical results are impactful.',\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. The reviewers unanimously acknowledge the clarity of the paper and the relevance of the theoretical contribution. Overall, this paper constitutes a good theoretical contribution at the intersection of causal representation learning and nonlinear ICA, which we recommend for acceptance.',\n",
              " 'This paper proposes a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. I agree with reviewer vdrw that, on the whole, the major contribution is that it avoids biases that are present in natural image datasets.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The paper presents an importnant contribution to multi-task RL problem.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers expressed concerns about generalization of the approach to different datasets.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Your summary should be between 2 to 4 sentences long. Focus on highlighting the main contributions, strengths, weaknesses, and overall recommendation as evaluated by the reviewers. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " \"Your task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. The reviewers have reached consensus after processing the reviewers' feedback. They all agree that this paper presents an interesting approach to applying variational inference in a setting of probabilistic programming that is of interest to the community.\",\n",
              " 'Your task is to generate summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning]. Ensure that the summary is concise, informative, and accurately represents the content of the paper. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions.',\n",
              " 'The paper introduces a novel neural network training approach, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The reviewers agreed with reviewers that the whole approach fits perfectly together and provides the reader with some nice and useful observations.',\n",
              " \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The additional experiments provided during the rebuttal strengthen the paper's contribution claim.\",\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. Overall, the paper received a positive recommendation with minor revisions. The authors did a good job addressing concerns from the reviewers, especially with the additional ablation studies to decouple the gains from other techniques such as SupCon.',\n",
              " 'This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised about generalization of the approach to different datasets. Overall, the paper received a positive recommendation with minor revisions.']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # input = df_metareviews.Metareview[0]\n",
        "  # pipe3(SUMMARIZATION_PROMPT.format(metareview=input))[0][\"summary_text\"]"
      ],
      "metadata": {
        "id": "tTI6A49A5zwj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input = df_metareviews.Metareview[0]\n",
        "# input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WUjkwFxa8v1F",
        "outputId": "ccb3c2a5-568d-4277-8b9b-f1b1ef8c165e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This paper proposes a class of neural processes that lifts the limitations of conditional neural processes (CNPs) and produces dependent/correlated outputs but that, as CNPs, is inherently scalable and it is easy to train via maximum likelihood. The proposed model is extended to multi-output regression and to capture non-Gaussian output distributions. Results are presented on synthetic data, an electroencephalogram dataset and on a climate modeling problem. The paper parameterizes the prediction map as a Gaussian, where the mean and covariance are determined using neural networks. Non-Gaussian prediction maps are obtained using copulas. \\n\\nTechnically speaking, the reviewers found the approach to be incremental and only marginally significant and I agree with them. Issues such as estimates of computational cost, using fixed lengthscales for the covariances and relationships/using normalizing flows have been addressed by the authors satisfactorily. Empirically, the contribution of the paper is somewhat significant, as it provides similar flexibility to other more computationally expensive processes and more general assumptions than conditional neural processes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SUMMARIZATION_PROMPT.format(metareview=input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "aZxWQRGm7lN5",
        "outputId": "5c8237d5-3325-4b8b-fb4d-73c038651636"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYour task is to generate concise summaries for the metareviews of various papers in the field of [insert specific field, e.g., machine learning].\\n\\nInstructions:\\n\\nRead the provided metareview carefully.\\nUse the information from the metareview to generate a summary that captures the key points and findings of the paper\\'s review process.\\nEnsure that the summary is concise, informative, and accurately represents the content of the metareview.\\nYour summary should be between 2 to 4 sentences long.\\nFocus on highlighting the main contributions, strengths, weaknesses, and overall recommendation of the paper as evaluated by the reviewers.\\nExample Metareview:\\n\\nMetareview: \"This paper proposes a novel approach to neural network training, leveraging recent advancements in optimization techniques. Reviewers found the experimental results compelling, demonstrating significant improvements over existing methods. However, some concerns were raised regarding the generalization of the approach to different datasets. Overall, the paper was recommended for acceptance with minor revisions.\"\\n\\nSample Summary:\\n\\nSummary: \"The paper introduces a novel neural network training approach, showing promising results in experiments. Reviewers highlighted its potential for significant advancements in the field, although some concerns about generalization were noted. Overall, the paper received a positive recommendation with minor revisions.\"\\n\\nYour Task:\\n\\nUsing the information provided in the metareview dataframe, generate summaries for each metareview following the instructions above. Ensure that your summaries are informative and capture the essence of each review effectively.\\nThis paper proposes a class of neural processes that lifts the limitations of conditional neural processes (CNPs) and produces dependent/correlated outputs but that, as CNPs, is inherently scalable and it is easy to train via maximum likelihood. The proposed model is extended to multi-output regression and to capture non-Gaussian output distributions. Results are presented on synthetic data, an electroencephalogram dataset and on a climate modeling problem. The paper parameterizes the prediction map as a Gaussian, where the mean and covariance are determined using neural networks. Non-Gaussian prediction maps are obtained using copulas. \\n\\nTechnically speaking, the reviewers found the approach to be incremental and only marginally significant and I agree with them. Issues such as estimates of computational cost, using fixed lengthscales for the covariances and relationships/using normalizing flows have been addressed by the authors satisfactorily. Empirically, the contribution of the paper is somewhat significant, as it provides similar flexibility to other more computationally expensive processes and more general assumptions than conditional neural processes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe3(SUMMARIZATION_PROMPT.format(metareview=input))[0][\"summary_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "TBvNwQwp8z1B",
        "outputId": "62fc1c4c-87a2-4200-d7f2-ee95e41bb23f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This paper proposes a class of neural processes that lifts the limitations of conditional neural processes (CNPs) and produces dependent/correlated outputs but that, as CNPs, is inherently scalable and it is easy to train via maximum likelihood. The proposed model is extended to multi-output regression and to capture non-Gaussian output distributions. The paper parameterizes the prediction map as a Gaussian, where the mean and covariance are determined using neural networks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}